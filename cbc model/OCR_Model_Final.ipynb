{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CBC IMAGE PREDICTOR (Using Saved Model + Raw Data for Normalization)"
      ],
      "metadata": {
        "id": "utOx7LW2uLVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- 1) Install OCR Tools ---"
      ],
      "metadata": {
        "id": "cHRgqJhFFVfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Installing OCR tools...\")\n",
        "!sudo apt-get install tesseract-ocr > /dev/null\n",
        "!pip install pytesseract > /dev/null\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THWEOKkUFXsn",
        "outputId": "380892c5-686d-4b7a-dd29-09c35e557ac1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing OCR tools...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- 2) Imports ---"
      ],
      "metadata": {
        "id": "euF8A2hxFZya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "ufMGpPBpFcH6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- 3) Configuration ---"
      ],
      "metadata": {
        "id": "g3qWiAeDFeex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_FILE = \"/content/drive/MyDrive/ML for CBC Project/best_model_pipeline.joblib\"\n",
        "RAW_DATA_FILE = \"/content/cbc_dataframe.csv\"\n",
        "IMAGE_FILE = \"/content/ubnormal.jpg\""
      ],
      "metadata": {
        "id": "7IkZcgIkFhKs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- 4) Load Resources ---"
      ],
      "metadata": {
        "id": "GtBmawuGFn7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n--- Loading Model and Data ---\")\n",
        "\n",
        "# A. Load the Saved Model\n",
        "try:\n",
        "    saved_bundle = joblib.load(MODEL_FILE)\n",
        "    model_pipeline = saved_bundle['pipeline']\n",
        "    label_encoder = saved_bundle['label_encoder']\n",
        "    required_features = saved_bundle['feature_columns']\n",
        "    print(\"Model loaded successfully\")\n",
        "    print(f\"Model expects {len(required_features)} features: {required_features}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    raise\n",
        "\n",
        "# B. Create the \"Translator\" (Scaler) using Raw Data\n",
        "# We DO NOT train the model. We just learn the Mean/Std Dev to normalize inputs.\n",
        "print(\"   Building Normalizer (Scaler) from raw data...\")\n",
        "try:\n",
        "    df_raw = pd.read_csv(RAW_DATA_FILE)\n",
        "\n",
        "    # 1. Calculate NLR if missing (Model expects it)\n",
        "    # Use a safe calculation handling zeros\n",
        "    ne = df_raw['NE#'] if 'NE#' in df_raw else df_raw.get('NE', 0)\n",
        "    ly = df_raw['LY#'] if 'LY#' in df_raw else df_raw.get('LY', 0)\n",
        "\n",
        "    # Simple vector calculation for the scaler fitting\n",
        "    df_raw['NLR'] = np.where(ly > 0, ne / ly, 0)\n",
        "\n",
        "    # 2. Select ONLY the columns the model needs\n",
        "    # We handle potential missing columns in raw data by filling with 0 temporarily for fitting\n",
        "    for col in required_features:\n",
        "        if col not in df_raw.columns:\n",
        "            print(f\"   Warning: '{col}' missing in raw data. Filling with median.\")\n",
        "            df_raw[col] = df_raw.select_dtypes(include=np.number).median().mean()\n",
        "\n",
        "    X_raw_for_scaling = df_raw[required_features]\n",
        "\n",
        "    # 3. Fit the Scaler\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_raw_for_scaling)\n",
        "    print(\"Normalizer ready. (Learned stats from raw CSV)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error building normalizer: {e}\")\n",
        "    print(\"Please ensure 'cbc_dataframe.csv' is uploaded.\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vJZDIobFnrF",
        "outputId": "a98fea81-d92c-4691-b996-05a42211c3e1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Loading Model and Data ---\n",
            "Model loaded successfully\n",
            "Model expects 21 features: ['WBC', 'LY%', 'MO%', 'NE%', 'EO%', 'BA%', 'LY#', 'MO#', 'NE#', 'EO#', 'BA#', 'RBC', 'HGB', 'HCT', 'MCV', 'MCHC', 'MCH', 'RDW', 'PLT', 'MPV', 'NLR']\n",
            "   Building Normalizer (Scaler) from raw data...\n",
            "Normalizer ready. (Learned stats from raw CSV)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- 5) The OCR Function ---"
      ],
      "metadata": {
        "id": "2MdNrtilFvaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data_from_image(image_path, feature_list):\n",
        "    print(f\"\\n--- Scanning Image: {image_path} ---\")\n",
        "    try:\n",
        "        text = pytesseract.image_to_string(Image.open(image_path))\n",
        "    except Exception as e:\n",
        "        print(f\"OCR Error: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Expanded Synonyms Dictionary to catch full names\n",
        "    synonyms = {\n",
        "        # White Blood Cells\n",
        "        'WBC': ['WBC', 'WHITE BLOOD', 'LEUKOCYTE', 'TOTAL LEUCOCYTIC COUNT', 'TLC'],\n",
        "        'LY%': ['LY%', 'LYM%', 'LYMPHOCYTE %', 'LYMPHOCYTES %'],\n",
        "        'MO%': ['MO%', 'MON%', 'MONOCYTE %', 'MONOCYTES %'],\n",
        "        'NE%': ['NE%', 'NEU%', 'NEUTROPHIL %', 'NEUTROPHILS %', 'POLY %', 'SEGMENTED'],\n",
        "        'EO%': ['EO%', 'EOS%', 'EOSINOPHIL %', 'EOSINOPHILS %'],\n",
        "        'BA%': ['BA%', 'BAS%', 'BASOPHIL %', 'BASOPHILS %'],\n",
        "\n",
        "        # Absolute Counts\n",
        "        'LY#': ['LY#', 'LYM#', 'ABS LYMPH', 'ABSOLUTE LYMPHOCYTE'],\n",
        "        'MO#': ['MO#', 'MON#', 'ABS MONO', 'ABSOLUTE MONOCYTE'],\n",
        "        'NE#': ['NE#', 'NEU#', 'ABS NEUT', 'ABSOLUTE NEUTROPHIL'],\n",
        "        'EO#': ['EO#', 'EOS#', 'ABS EOS', 'ABSOLUTE EOSINOPHIL'],\n",
        "        'BA#': ['BA#', 'BAS#', 'ABS BASO', 'ABSOLUTE BASOPHIL'],\n",
        "\n",
        "        # Red Blood Cells\n",
        "        'RBC': ['RBC', 'RED BLOOD', 'ERYTHROCYTE', 'TOTAL RBC'],\n",
        "        'HGB': ['HGB', 'HEMOGLOBIN', 'HAEMOGLOBIN'], # 'HAEMOGLOBIN' is common in non-US reports\n",
        "        'HCT': ['HCT', 'HEMATOCRIT', 'PACKED CELL VOLUME', 'PCV'],\n",
        "\n",
        "        # Indices\n",
        "        'MCV': ['MCV', 'MEAN CORPUSCULAR VOLUME'],\n",
        "        'MCH': ['MCH', 'MEAN CORPUSCULAR HEMOGLOBIN'],\n",
        "        'MCHC': ['MCHC', 'MEAN CORP. HEM. CONC'],\n",
        "        'RDW': ['RDW', 'RED CELL DISTRIBUTION'],\n",
        "\n",
        "        # Platelets\n",
        "        'PLT': ['PLT', 'PLATELET', 'THROMBOCYTE', 'PLATELET COUNT'],\n",
        "        'MPV': ['MPV', 'MEAN PLATELET VOLUME']\n",
        "    }\n",
        "\n",
        "    extracted = {}\n",
        "    text_upper = text.upper()\n",
        "\n",
        "    for feature in feature_list:\n",
        "        if feature == 'NLR': continue # Calculated later\n",
        "\n",
        "        terms = synonyms.get(feature, [feature])\n",
        "        val = None\n",
        "        for term in terms:\n",
        "            # Regex: Look for Term -> Optional Separators -> Number\n",
        "            # Handles: \"WBC: 8.5\", \"WBC 8.5\", \"WBC - 8.5\"\n",
        "            pattern = re.escape(term) + r\"[\\s:\\.-]*([\\d\\.]+)\"\n",
        "            match = re.search(pattern, text_upper)\n",
        "            if match:\n",
        "                try:\n",
        "                    val_str = match.group(1)\n",
        "                    # Fix OCR glitches like \"8.5.2\" -> \"8.5\"\n",
        "                    if val_str.count('.') > 1: val_str = val_str.rsplit('.', 1)[0]\n",
        "                    val = float(val_str)\n",
        "                    print(f\"  Found {feature}: {val}\")\n",
        "                    break\n",
        "                except: continue\n",
        "\n",
        "        extracted[feature] = val\n",
        "\n",
        "    return extracted"
      ],
      "metadata": {
        "id": "-3te2CAqFy70"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- 6) The Main Application ---"
      ],
      "metadata": {
        "id": "KVNUl_IVF3pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_diagnosis(image_path):\n",
        "    if not os.path.exists(image_path):\n",
        "        print(\"Error: Image file not found.\")\n",
        "        return\n",
        "\n",
        "    # A. Extract\n",
        "    data = extract_data_from_image(image_path, required_features)\n",
        "    if not data: return\n",
        "\n",
        "    # B. Calc Hidden Feature\n",
        "    ne = data.get('NE#')\n",
        "    ly = data.get('LY#')\n",
        "    if ne is not None and ly is not None and ly > 0:\n",
        "        data['NLR'] = ne / ly\n",
        "        print(f\"  Calculated NLR: {data['NLR']:.2f}\")\n",
        "    else:\n",
        "        data['NLR'] = None\n",
        "\n",
        "    # C. Prepare DataFrame\n",
        "    input_df = pd.DataFrame([data])\n",
        "\n",
        "    # Ensure all columns exist\n",
        "    for col in required_features:\n",
        "        if col not in input_df.columns:\n",
        "            input_df[col] = np.nan\n",
        "\n",
        "    # Reorder\n",
        "    input_df = input_df[required_features]\n",
        "\n",
        "    # --- CRITICAL FIX: Force everything to be a Number ---\n",
        "    input_df = input_df.apply(pd.to_numeric, errors='coerce')\n",
        "    # -----------------------------------------------------\n",
        "\n",
        "    # D. Normalize\n",
        "    print(\"\\n--- Normalizing Data ---\")\n",
        "    try:\n",
        "        input_values = input_df.values\n",
        "\n",
        "        # Fill NaNs with column means from scaler (safe handling)\n",
        "        col_means = scaler.mean_\n",
        "        inds = np.where(np.isnan(input_values))\n",
        "        input_values[inds] = np.take(col_means, inds[1])\n",
        "\n",
        "        # Scale\n",
        "        input_scaled = scaler.transform(input_values)\n",
        "\n",
        "        # E. Predict\n",
        "        print(\"--- Making Prediction ---\")\n",
        "        pred_idx = model_pipeline.predict(input_scaled)[0]\n",
        "        diagnosis = label_encoder.inverse_transform([pred_idx])[0]\n",
        "\n",
        "        # Probabilities\n",
        "        if hasattr(model_pipeline, \"predict_proba\"):\n",
        "            confidence = np.max(model_pipeline.predict_proba(input_scaled)) * 100\n",
        "        else:\n",
        "            confidence = 0.0\n",
        "\n",
        "        print(\"\\n\" + \"#\"*40)\n",
        "        print(f\"  RESULT: {diagnosis}\")\n",
        "        if confidence > 0:\n",
        "            print(f\"  Confidence: {confidence:.2f}%\")\n",
        "        print(\"#\"*40)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Prediction Error: {e}\")"
      ],
      "metadata": {
        "id": "dyHzWTtYF6AV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_diagnosis(IMAGE_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DUIri3GF96_",
        "outputId": "2c2dee46-6ca1-406c-f11f-8bce6261536e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Scanning Image: /content/ubnormal.jpg ---\n",
            "  Found HGB: 106.0\n",
            "  Found MCV: 836.0\n",
            "  Found MCH: 26.5\n",
            "  Found PLT: 150.0\n",
            "  Found MPV: 10.4\n",
            "\n",
            "--- Normalizing Data ---\n",
            "--- Making Prediction ---\n",
            "\n",
            "########################################\n",
            "  RESULT: Thrombocytopenia\n",
            "  Confidence: 88.00%\n",
            "########################################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but SimpleImputer was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "#   UPDATED OCR DIAGNOSTIC CELL (Checks All Synonyms)\n",
        "# ==========================================================\n",
        "import pytesseract\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "import re\n",
        "import os\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Change this to match your uploaded image filename!\n",
        "IMAGE_TO_CHECK = \"/content/ubnormal.jpg\"\n",
        "\n",
        "if os.path.exists(IMAGE_TO_CHECK):\n",
        "    print(f\"--- 1. RAW TEXT DUMP (What Tesseract sees) ---\")\n",
        "    try:\n",
        "        # Get the raw text\n",
        "        raw_text = pytesseract.image_to_string(Image.open(IMAGE_TO_CHECK))\n",
        "        text_upper = raw_text.upper()\n",
        "\n",
        "        # Print it with a border so you can see the quality\n",
        "        print(\"--------------------------------------------------\")\n",
        "        print(raw_text.strip())\n",
        "        print(\"--------------------------------------------------\")\n",
        "\n",
        "        print(f\"\\n--- 2. PARSING CHECK (Scanning for values...) ---\")\n",
        "\n",
        "        # The full dictionary of terms to search for\n",
        "        synonyms = {\n",
        "            # White Blood Cells\n",
        "            'WBC': ['WBC', 'WHITE BLOOD', 'LEUKOCYTE', 'TOTAL LEUCOCYTIC COUNT', 'TLC'],\n",
        "            'LY%': ['LY%', 'LYM%', 'LYMPHOCYTE %', 'LYMPHOCYTES %'],\n",
        "            'MO%': ['MO%', 'MON%', 'MONOCYTE %', 'MONOCYTES %'],\n",
        "            'NE%': ['NE%', 'NEU%', 'NEUTROPHIL %', 'NEUTROPHILS %', 'POLY %', 'SEGMENTED'],\n",
        "            'EO%': ['EO%', 'EOS%', 'EOSINOPHIL %', 'EOSINOPHILS %'],\n",
        "            'BA%': ['BA%', 'BAS%', 'BASOPHIL %', 'BASOPHILS %'],\n",
        "\n",
        "            # Absolute Counts\n",
        "            'LY#': ['LY#', 'LYM#', 'ABS LYMPH', 'ABSOLUTE LYMPHOCYTE'],\n",
        "            'MO#': ['MO#', 'MON#', 'ABS MONO', 'ABSOLUTE MONOCYTE'],\n",
        "            'NE#': ['NE#', 'NEU#', 'ABS NEUT', 'ABSOLUTE NEUTROPHIL'],\n",
        "            'EO#': ['EO#', 'EOS#', 'ABS EOS', 'ABSOLUTE EOSINOPHIL'],\n",
        "            'BA#': ['BA#', 'BAS#', 'ABS BASO', 'ABSOLUTE BASOPHIL'],\n",
        "\n",
        "            # Red Blood Cells\n",
        "            'RBC': ['RBC', 'RED BLOOD', 'ERYTHROCYTE', 'TOTAL RBC'],\n",
        "            'HGB': ['HGB', 'HEMOGLOBIN', 'HAEMOGLOBIN'],\n",
        "            'HCT': ['HCT', 'HEMATOCRIT', 'PACKED CELL VOLUME', 'PCV'],\n",
        "\n",
        "            # Indices\n",
        "            'MCV': ['MCV', 'MEAN CORPUSCULAR VOLUME'],\n",
        "            'MCH': ['MCH', 'MEAN CORPUSCULAR HEMOGLOBIN'],\n",
        "            'MCHC': ['MCHC', 'MEAN CORP. HEM. CONC'],\n",
        "            'RDW': ['RDW', 'RED CELL DISTRIBUTION'],\n",
        "\n",
        "            # Platelets\n",
        "            'PLT': ['PLT', 'PLATELET', 'THROMBOCYTE', 'PLATELET COUNT'],\n",
        "            'MPV': ['MPV', 'MEAN PLATELET VOLUME']\n",
        "        }\n",
        "\n",
        "        # Loop through every feature and try every synonym\n",
        "        for feature, search_terms in synonyms.items():\n",
        "            found_val = None\n",
        "            matched_term = None\n",
        "\n",
        "            for term in search_terms:\n",
        "                # Regex: Look for Term -> Optional Separators -> Number\n",
        "                # Matches: \"WBC 8.5\", \"WBC: 8.5\", \"WBC - 8.5\"\n",
        "                pattern = re.escape(term) + r\"[\\s:\\.-]*([\\d\\.]+)\"\n",
        "                match = re.search(pattern, text_upper)\n",
        "\n",
        "                if match:\n",
        "                    val_str = match.group(1)\n",
        "                    # Fix common OCR glitch (e.g., \"8.5.2\" -> \"8.5\")\n",
        "                    if val_str.count('.') > 1: val_str = val_str.rsplit('.', 1)[0]\n",
        "\n",
        "                    found_val = val_str\n",
        "                    matched_term = term\n",
        "                    break # Stop searching synonyms for this feature\n",
        "\n",
        "            # Print results\n",
        "            if found_val:\n",
        "                print(f\"✅ {feature:<5} : Found '{found_val}' (Matched: '{matched_term}')\")\n",
        "            else:\n",
        "                # If completely missing, show what we looked for\n",
        "                print(f\"❌ {feature:<5} : NOT FOUND (Checked: {search_terms})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error running OCR: {e}\")\n",
        "else:\n",
        "    print(f\"Error: File '{IMAGE_TO_CHECK}' not found. Please check the filename.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx5Z1HWPLwmo",
        "outputId": "b2f38611-f03d-4bb3-db0e-6719ad16f445"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 1. RAW TEXT DUMP (What Tesseract sees) ---\n",
            "--------------------------------------------------\n",
            "TUT TEST REPORT\n",
            "Patient MR. TRIJUGEE NARAYAN SHUKLA. Reg. No. 2108121930\n",
            "Age/Gender :68 Y/Male Reg. Date 30-Aug-2021\n",
            "Ref. By SELF Report Date 30-Aug-2021\n",
            "Associate SRN DIAGNOSTICS INDORE Laboratory\n",
            "\n",
            "COMPLETE BLOOD COUNT (CBC)\n",
            "Parameter Observed Value Unit Biological Reference interval\n",
            "Hemoglobin 106 gat 13.0 - 17.0\n",
            "RBC Count 4.00 millionfemm 4.6 - 6.2\n",
            "Hematrocrit 33.4 % 40-54\n",
            "mcv 836 i 80 - 96\n",
            "McH 26.5 Pg 27-33\n",
            "McHe 7 % 32-36\n",
            "ROW: CV 142 % 11-16\n",
            "RDW-SD 50.1 fl 35 - 56\n",
            "PLATELET COUNT 150 10% iL 150 - 410\n",
            "MPV 10.4 a 65-120\n",
            "POW 265 2500 - 65.0\n",
            "TOTAL COUNT (WBC), EDTA blood 863 10% 40-100\n",
            "DIFFERENTIAL WBC COUNT (Manual By Microscopy)\n",
            "Neutrophils (%) 80 % 38-70\n",
            "Lymphocytes (%) cr) % 20-45\n",
            "Monocytes (%) 03 % 2-8\n",
            "Eosinophils (%) 02 % 1-4\n",
            "Basophils (%) 00 % o-1\n",
            "Neutrophils (Abs) 695 10% iL\n",
            "Lymphocytes (Abs) 1.23 10%\n",
            "Monocytes (Abs) 036 10%\n",
            "Eosinophils (Abs) 0.02 10%L\n",
            "Basophils (Abs) 0.07 Jemm,\n",
            "\n",
            "Interpretation : The test is done on fully automated 5 PART cell counter of Mindray BC 5300'Specimen : WB-EDTA\n",
            "\n",
            " \n",
            "\n",
            "End of Report ~\n",
            "\n",
            " \n",
            "\n",
            "bak\n",
            "\n",
            "MD (PATHOLOGIST)\n",
            "\n",
            "Printed On: 30.08.2021 3:12 PM\n",
            "--------------------------------------------------\n",
            "\n",
            "--- 2. PARSING CHECK (Scanning for values...) ---\n",
            "❌ WBC   : NOT FOUND (Checked: ['WBC', 'WHITE BLOOD', 'LEUKOCYTE', 'TOTAL LEUCOCYTIC COUNT', 'TLC'])\n",
            "❌ LY%   : NOT FOUND (Checked: ['LY%', 'LYM%', 'LYMPHOCYTE %', 'LYMPHOCYTES %'])\n",
            "❌ MO%   : NOT FOUND (Checked: ['MO%', 'MON%', 'MONOCYTE %', 'MONOCYTES %'])\n",
            "❌ NE%   : NOT FOUND (Checked: ['NE%', 'NEU%', 'NEUTROPHIL %', 'NEUTROPHILS %', 'POLY %', 'SEGMENTED'])\n",
            "❌ EO%   : NOT FOUND (Checked: ['EO%', 'EOS%', 'EOSINOPHIL %', 'EOSINOPHILS %'])\n",
            "❌ BA%   : NOT FOUND (Checked: ['BA%', 'BAS%', 'BASOPHIL %', 'BASOPHILS %'])\n",
            "❌ LY#   : NOT FOUND (Checked: ['LY#', 'LYM#', 'ABS LYMPH', 'ABSOLUTE LYMPHOCYTE'])\n",
            "❌ MO#   : NOT FOUND (Checked: ['MO#', 'MON#', 'ABS MONO', 'ABSOLUTE MONOCYTE'])\n",
            "❌ NE#   : NOT FOUND (Checked: ['NE#', 'NEU#', 'ABS NEUT', 'ABSOLUTE NEUTROPHIL'])\n",
            "❌ EO#   : NOT FOUND (Checked: ['EO#', 'EOS#', 'ABS EOS', 'ABSOLUTE EOSINOPHIL'])\n",
            "❌ BA#   : NOT FOUND (Checked: ['BA#', 'BAS#', 'ABS BASO', 'ABSOLUTE BASOPHIL'])\n",
            "❌ RBC   : NOT FOUND (Checked: ['RBC', 'RED BLOOD', 'ERYTHROCYTE', 'TOTAL RBC'])\n",
            "✅ HGB   : Found '106' (Matched: 'HEMOGLOBIN')\n",
            "❌ HCT   : NOT FOUND (Checked: ['HCT', 'HEMATOCRIT', 'PACKED CELL VOLUME', 'PCV'])\n",
            "✅ MCV   : Found '836' (Matched: 'MCV')\n",
            "✅ MCH   : Found '26.5' (Matched: 'MCH')\n",
            "❌ MCHC  : NOT FOUND (Checked: ['MCHC', 'MEAN CORP. HEM. CONC'])\n",
            "❌ RDW   : NOT FOUND (Checked: ['RDW', 'RED CELL DISTRIBUTION'])\n",
            "✅ PLT   : Found '150' (Matched: 'PLATELET COUNT')\n",
            "✅ MPV   : Found '10.4' (Matched: 'MPV')\n"
          ]
        }
      ]
    }
  ]
}